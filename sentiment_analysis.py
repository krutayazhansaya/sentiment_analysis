# -*- coding: utf-8 -*-
"""Sentiment_analysis

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1AxoytzChnHyXMI-Ha4YtEoxL9liCExmv
"""

import pandas as pd
import re
import nltk
import string
import matplotlib.pyplot as plt

from bs4 import BeautifulSoup
from nltk.corpus import stopwords
from nltk.stem import WordNetLemmatizer
from nltk.tokenize import word_tokenize

from sklearn.feature_extraction.text import CountVectorizer
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.naive_bayes import MultinomialNB
from sklearn.metrics import f1_score, accuracy_score
from sklearn.metrics import classification_report

"""## 1. EDA"""

data = pd.read_csv("comments_data.csv", encoding='utf-8')
data.head()

data['Sentiment'] = data['Sentiment'].map({'positive': 1, 'negative': 0})

data["Sentiment"].value_counts()



null_values = data.isnull()
null_values.sum()

data=data.dropna()

# Checking for duplicates
duplicates = data.duplicated()
print("Number of duplicate rows:", duplicates.sum())

data=data.drop_duplicates()

# example_text = data["Comment"][4]
# example_text

"""#### 1.1 Data cleaning"""

def clean_text(text):

    # Remove HTML tags
    text = BeautifulSoup(text, "html.parser").get_text()

    # Remove additional HTML-like patterns
    text = re.sub(r'<.*?>', ' ', text)

    # Remove punctuation
    text = text.translate(str.maketrans('', '', string.punctuation))

    # Convert to lowercase
    text = text.lower()

    # Remove numbers
    text = re.sub(r'\d+', '', text)

    # Remove extra whitespace
    text = re.sub(r'\s+', ' ', text).strip()

    return text

# Apply the cleaning function
data['cleaned_comments'] = data['Comment'].apply(clean_text)
data.to_csv("comments_data.csv", index=False)

example = data["Comment"][50]

print(example)
print(' ')
print(data['cleaned_comments'][50])

import seaborn as sns

plt.figure(figsize=(6,4))
sns.countplot(x='Sentiment', data=data, palette="viridis")
plt.title('Распределение целевой переменной')
plt.xlabel("Sentiment")
plt.ylabel("Количество")
plt.show()

# Download necessary NLTK resources
nltk.download('punkt_tab')
nltk.download('wordnet')

# Tokenization and Lemmatization
lemmatizer = WordNetLemmatizer()

def tokenize_and_lemmatize(text):
    tokens = word_tokenize(text)  # Tokenization
    lemmatized_tokens = [lemmatizer.lemmatize(token) for token in tokens]  # Lemmatization
    return ' '.join(lemmatized_tokens)

# Process the reviews
data['processed_comments'] = data['cleaned_comments'].apply(tokenize_and_lemmatize)

"""Comments:

## 2. Data Visualization

Wordclouds
"""

!pip install wordcloud

from wordcloud import WordCloud

# Word Cloud for all reviews
all_reviews = ' '.join(data['processed_comments'])
wordcloud_all = WordCloud(width=800, height=400, background_color='white').generate(all_reviews)

plt.figure(figsize=(10, 5))
plt.imshow(wordcloud_all, interpolation='bilinear')
plt.axis('off')
plt.title('Word Cloud for All Comments')
plt.show()

"""Adding length column"""

data['comments_length'] = data['processed_comments'].apply(lambda x: len(x.split()))
data.head()

# Visualize Review Length Distribution
import seaborn as sns

plt.figure(figsize=(10, 5))
plt.xlim(0, 200)  # keep only up to 200 words on x-axis
sns.histplot(data['comments_length'], bins=50, kde=True)
plt.title('Distribution of Review Lengths')
plt.xlabel('Length of Review (in Words)')
plt.ylabel('Frequency')
plt.show()



"""Comments:

## 3. Vectorization
"""

import pandas as pd
from imblearn.over_sampling import RandomOverSampler

# Загружаем CSV
df = pd.read_csv("comments_data.csv")

# Фичи и таргет
X = data["processed_comments"].astype(str)   # тексты
y = data["Sentiment"]                        # метки

# Oversampling
ros = RandomOverSampler(random_state=42)
X_resampled, y_resampled = ros.fit_resample(X.to_numpy().reshape(-1, 1), y)

# Превращаем обратно в DataFrame
df_balanced = pd.DataFrame({
    "processed_comments": X_resampled.flatten(),
    "Sentiment": y_resampled
})

print(df_balanced["Sentiment"].value_counts())

#balancing the data

# Vectorization using Bag of Words (BoW)
bow_vectorizer = CountVectorizer()
X_bow = bow_vectorizer.fit_transform(data['processed_comments'])
y = data['Sentiment']

# Split the data for BoW
X_train_bow, X_test_bow, y_train, y_test = train_test_split(X_bow, y, test_size=0.2, random_state=42)

# Vectorization using TF-IDF
from sklearn.feature_extraction.text import TfidfVectorizer

tfidf_vectorizer = TfidfVectorizer()
X_tfidf = tfidf_vectorizer.fit_transform(data['processed_comments'])

# Split the data for TF-IDF
X_train_tfidf, X_test_tfidf, y_train, y_test = train_test_split(X_tfidf, y, test_size=0.2, random_state=42)

"""Comments:

## 4. Model building and evaluation
"""

from sklearn.svm import SVC

models = {
    "Logistic Regression": LogisticRegression(max_iter=1000, n_jobs=-1),
    "Random Forest": RandomForestClassifier(n_estimators=20, n_jobs=-1),
    "Naive Bayes": MultinomialNB(),
    "Support Vector Machine": SVC(kernel='linear')
}


# Store results
results = {
    "BoW": {},
    "TF-IDF": {}
}

# Function to train and evaluate models
def evaluate_models(X_train, X_test, y_train, y_test, vectorization_method):

    for model_name, model in models.items():
        # Train the model
        model.fit(X_train, y_train)

        # Make predictions
        y_pred = model.predict(X_test)

        # Evaluate the model
        accuracy = accuracy_score(y_test, y_pred)
        report = classification_report(y_test, y_pred, output_dict=True)

        results[vectorization_method][model_name] = {
            "Accuracy": accuracy,
            "Precision": report['weighted avg']['precision'],
            "Recall": report['weighted avg']['recall'],
            "F1 Score": report['weighted avg']['f1-score']
        }

        print(f"{model_name} was trained")

# Evaluate models using BoW
evaluate_models(X_train_bow, X_test_bow, y_train, y_test, "BoW")

# Evaluate models using TF-IDF
evaluate_models(X_train_tfidf, X_test_tfidf, y_train, y_test, "TF-IDF")

# Convert results to DataFrame for better visualization
results_df = pd.DataFrame({(i, j): results[i][j] for i in results.keys() for j in results[i].keys()})
results_df = results_df.T

results_df

"""Two best models are (as they have higher F1 score)
1. Bag-of-Words + Logistic Regression
2. Bag-of-Words + Support Vector Machine
"""

import pandas as pd
from sklearn.feature_extraction.text import CountVectorizer
from sklearn.linear_model import LogisticRegression
from sklearn.svm import SVC
from sklearn.model_selection import GridSearchCV, cross_val_score
from sklearn.pipeline import Pipeline
from sklearn.metrics import classification_report, make_scorer, f1_score

# --- 1. Данные ---
X = df["cleaned_comments"]   # тексты
y = df["Sentiment"]          # метки (0/1)

# --- 2. Пайплайны ---
logreg_pipeline = Pipeline([
    ("bow", CountVectorizer()),
    ("clf", LogisticRegression(max_iter=1000, random_state=42))
])

svm_pipeline = Pipeline([
    ("bow", CountVectorizer()),
    ("clf", SVC(random_state=42))
])

# --- 3. Гриды гиперпараметров ---
logreg_param_grid = {
    "bow__ngram_range": [(1,1), (1,2)],          # униграммы vs уни+би
    "clf__C": [0.01, 0.1, 1, 10],                # регуляризация
    "clf__penalty": ["l2"],                      # только L2
    "clf__solver": ["lbfgs", "liblinear"]        # разные решатели
}

svm_param_grid = {
    "bow__ngram_range": [(1,1), (1,2)],
    "clf__C": [0.1, 1, 10],
    "clf__kernel": ["linear", "rbf"]             # разные ядра
}

# --- 4. Оптимизация через GridSearchCV ---
scorer = make_scorer(f1_score, average="binary")

logreg_grid = GridSearchCV(logreg_pipeline, logreg_param_grid,
                           cv=5, scoring=scorer, n_jobs=-1, verbose=1)
svm_grid = GridSearchCV(svm_pipeline, svm_param_grid,
                        cv=5, scoring=scorer, n_jobs=-1, verbose=1)

# --- 5. Обучение и подбор ---
print("=== Logistic Regression (Bag-of-Words) ===")
logreg_grid.fit(X, y)
print("Лучшие гиперпараметры:", logreg_grid.best_params_)
print("Лучший F1-score:", logreg_grid.best_score_)

print("\n=== Support Vector Machine (Bag-of-Words) ===")
svm_grid.fit(X, y)
print("Лучшие гиперпараметры:", svm_grid.best_params_)
print("Лучший F1-score:", svm_grid.best_score_)

"""Logistic Regression (Bag-of-Words) лучше. Так как F1 выше (0.932635337335596)

> Add blockquote

# Part-2 - Using pre-trained models

Refer to P7-2 file
"""

import torch
from transformers import AutoTokenizer, AutoModelForSequenceClassification
from datasets import load_dataset
dataset = load_dataset("csv", data_files="comments_data.csv")

# Load the tokenizer and model
model_name = "distilbert-base-uncased-finetuned-sst-2-english"

tokenizer = AutoTokenizer.from_pretrained(model_name)
model = AutoModelForSequenceClassification.from_pretrained(model_name)

def preprocess_function(examples):
    texts = [str(t) for t in examples["cleaned_comments"]]
    return tokenizer(texts, truncation=True, padding="max_length", max_length=128)

# Обрабатываем именно dataset["train"]
tokenized_dataset = dataset.map(preprocess_function, batched=True)

# def analyze_sentiment(text):
#     result = sentiment_pipeline(text)[0]   # вернёт dict
#     return pd.Series({
#         "sentiment_label": result["label"],
#         "sentiment_score": result["score"]
#     })

# df[["sentiment_label", "sentiment_score"]] = df["cleaned_comments"].apply(analyze_sentiment)
from transformers import pipeline

# Создаём пайплайн с усечением
sentiment_pipeline = pipeline(
    "sentiment-analysis",
    model="distilbert-base-uncased-finetuned-sst-2-english",
    truncation=True,
    max_length=512
)

def analyze_sentiment(text):
    result = sentiment_pipeline(text)[0]
    return pd.Series({
        "sentiment_label": result["label"],
        "sentiment_score": result["score"]
    })

df[["sentiment_label", "sentiment_score"]] = df["cleaned_comments"].astype(str).apply(analyze_sentiment)

sample = pd.DataFrame({
    "review": data["cleaned_comments"][:5],
    "sentiment": data["Sentiment"][:5]
})

print(sample)

# Берем тексты для анализа (список строк)
sample_reviews = data["cleaned_comments"][:5].tolist()

# Запускаем анализ
predictions = sentiment_pipeline(sample_reviews)  # это список словарей

# Достаём метки и confidence
labels = [pred["label"] for pred in predictions]
scores = [pred["score"] for pred in predictions]

# Выводим
for review, sentiment, score in zip(sample_reviews, labels, scores):
    print(f"Review: {review}\nPredicted Sentiment: {sentiment} (score={score:.4f})\n")

from transformers import pipeline
from datasets import load_dataset

# # Загружаем CSV в формате HuggingFace
# dataset = load_dataset("csv", data_files="comments_data.csv")["train"]

# # Создаём пайплайн
# sentiment_pipeline = pipeline(
#     "sentiment-analysis",
#     model="distilbert-base-uncased-finetuned-sst-2-english",
#     device=-1,   # CPU (-1), или 0 если есть GPU
#     truncation=True,
#     max_length=128
# )

import pandas as pd
from transformers import pipeline
from datasets import load_dataset
from tqdm.auto import tqdm

# Load the IMDb dataset
dataset = load_dataset("csv", data_files="comments_data.csv")["train"]

# Prepare the sentiment analysis pipeline
sentiment_pipeline = pipeline(
    "sentiment-analysis",
    model="distilbert-base-uncased-finetuned-sst-2-english",
    device=0,  # Use GPU if available
    truncation=True,
    max_length=512
)

# Убедимся, что в колонке только строки и нет NaN
df["cleaned_comments"] = df["cleaned_comments"].fillna("").astype(str)

# Прогоняем все комментарии через модель
sentiment_results = sentiment_pipeline(df["cleaned_comments"].tolist())

# Превращаем в DataFrame
all_comments = pd.DataFrame(sentiment_results)

# Добавляем сами тексты
all_comments["cleaned_comments"] = df["cleaned_comments"].values

# Переводим метки в числа
sentiment_mapping = {"NEGATIVE": 0, "POSITIVE": 1}
all_comments["sentiment"] = all_comments["label"].map(sentiment_mapping)

print(all_comments.head())

all_comments

import pandas as pd
from sklearn.metrics import accuracy_score, precision_recall_fscore_support

# 1. Реальные метки (они уже 0 и 1)
actual_labels = df["Sentiment"]

# 2. Предсказания модели
predictions = sentiment_pipeline(df["cleaned_comments"].tolist())
all_comments = pd.DataFrame(predictions)

# 3. Маппинг только для предсказаний
sentiment_mapping = {"NEGATIVE": 0, "POSITIVE": 1}
all_comments["predicted"] = all_comments["label"].map(sentiment_mapping)

# 4. Добавляем реальные метки
all_comments["actual"] = actual_labels.values

# 5. Убираем строки с NaN (на всякий случай)
all_comments = all_comments.dropna(subset=["actual", "predicted"])

# 6. Метрики
accuracy = accuracy_score(all_comments["actual"], all_comments["predicted"])
precision, recall, f1, _ = precision_recall_fscore_support(
    all_comments["actual"], all_comments["predicted"], average="binary"
)

print(f"Accuracy: {accuracy:.4f}")
print(f"Precision: {precision:.4f}")
print(f"Recall: {recall:.4f}")
print(f"F1 Score: {f1:.4f}")

"""Comments:

# Comparison

Compare metrics results of ML model and pre-trained model
"""

Logistic Regression (Bag-of-Words) F1 (0.932635337335596) показывает лучше результат чем  BERT F1 Score (0.8864).

"""BERT:
Учитывает контекст и порядок слов.
Высокая точность (Precision = 0.97). Recall ниже (0.81), пропускает часть примеров. Требует много ресурсов и дообучения.
Logistic Regression (Bag-of-Words):
Простая, быстрая и интерпретируемая. Более высокий F1 (0.93) → лучше сбалансирована Precision/Recall Не понимает контекст и порядок слов

Comments:
"""